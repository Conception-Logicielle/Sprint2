==============================
Fichier        : ACL2004-HEADLINE.txt
Titre          : Hybrid Headlines: Combining Topics and Sentence Compres David Zajic, Bonnie Dorr, Stacy President Department of Computer Science
Résumé         : This paper presents Topiary, a headlinegeneration system that creates very short, informative summaries for news stories by combining sentence compression and unsupervised topic discovery. We will show that the combination of linguistically motivated sentence compression with statistically selected topic terms performs better than either alone, according to some automatic summary evaluation measures. In addition we describe experimental results establishing an appropriate extrinsic task on which to measure the effect of summarization on human performance. We demonstrate the usefulness of headlines in comparison to full texts in the context of this extrinsic task.
Lignes totales : 424
Lignes résumé  : 19
Longueur texte : 671 caractères
Temps analyse  : 4 ms

==============================
Traitement terminé en 4 ms
==============================
Fichier        : Boudin-Torres-2006.txt
Titre          : A Scalable MMR Approach to Sentence Scoring for Multi-Document Update Summarization Florian Boudin and Marc El-Be`ze
Résumé         : We present SMMR, a scalable sentence scoring method for query-oriented update summarization. Sentences are scored thanks to a criterion combining query relevance and dissimilarity with already read documents (history). As the amount of data in history increases, non-redundancy is prioritized over query-relevance. We show that SMMR achieves promising results on the DUC 2007 update corpus.
Lignes totales : 285
Lignes résumé  : 11
Longueur texte : 390 caractères
Temps analyse  : 2 ms

==============================
Traitement terminé en 6 ms
==============================
Fichier        : compression.txt
Titre          : Multi-Candidate Reduction: Sentence Compression as a Tool for Document Summarization Tasks∗ David Zajic1, Bonnie J. Dorr1, Jimmy Lin1, Richard Schwartz2
Résumé         : This article examines the application of two single-document sentence compression techniques to the problem of multi-document summarization—a “parse-and-trim” approach and a statistical noisy-channel approach. We introduce the Multi-Candidate Reduction (MCR) framework for multi-document summarization, in which many compressed candidates are generated for each source sentence. These candidates are then selected for inclusion in the ﬁnal summary based on a combination of static and dynamic features. Evaluations demonstrate that sentence compression is a valuable component of a larger multi-document summarization framework. Keywords: headline generation, summarization, parse-and-trim, Hidden Markov Model PACS: Artiﬁcial intelligence, 07.05.Mh; Computer science and technology, 89.20.Ff; Spoken languages, processing of, 43.71.Sy
Lignes totales : 1422
Lignes résumé  : 13
Longueur texte : 845 caractères
Temps analyse  : 7 ms

==============================
Traitement terminé en 14 ms
==============================
Fichier        : compression_phrases_Prog-Linear-jair.txt
Titre          : Journal of Artiﬁcial Intelligence Research 31 (2008) 399-429 Submitted 09/07; published 03/08 Global Inference for Sentence Compression An Integer Linear Programming Approach
Résumé         : Sentence compression holds promise for many applications ranging from summarization to subtitle generation. Our work views sentence compression as an optimization problem and uses integer linear programming (ILP) to infer globally optimal compressions in the presence of linguistically motivated constraints. We show how previous formulations of sentence compression can be recast as ILPs and extend these models with novel global constraints. Experimental results on written and spoken texts demonstrate improvements over state-of-the-art models.
Lignes totales : 1799
Lignes résumé  : 8
Longueur texte : 547 caractères
Temps analyse  : 9 ms

==============================
Traitement terminé en 23 ms
==============================
Fichier        : hybrid_approach.txt
Titre          : Sentence Compression for Automated Subtitling: A Hybrid Vincent Vandeghinste and Centre for Computational
Résumé         : 
Lignes totales : 432
Lignes résumé  : 0
Longueur texte : 0 caractères
Temps analyse  : 3 ms

==============================
Traitement terminé en 27 ms
==============================
Fichier        : marcu_statistics_sentence_pass_one.txt
Titre          : 
Résumé         : When humans produce summaries of documents, they do not simply extract sentences and concatenate them. Rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. Given that large collections of text/abstract pairs are available online, it is now possible to envisi algorithms that are trained to mimic this process. In this paper, we focus on sentence compression, a simpler version of this larger challenge. We aim to achieve two goals simultaneously: our compressions should be grammatical, and they should retain the most important pieces of information. These two goals can conﬂict. We devise both noisy-channel and decision-tree approaches to the problem, and we evaluate results against manual compressions and a simple baseline.
Lignes totales : 550
Lignes résumé  : 17
Longueur texte : 846 caractères
Temps analyse  : 3 ms

==============================
Traitement terminé en 30 ms
==============================
Fichier        : mikheev.txt
Titre          : Periods, Capitalized Words, etc. Andrei Mikheev∗ University of Edinburgh
Résumé         : 
Lignes totales : 1802
Lignes résumé  : 0
Longueur texte : 0 caractères
Temps analyse  : 9 ms

==============================
Traitement terminé en 40 ms
==============================
Fichier        : probabilistic_sentence_reduction.txt
Titre          : Probabilistic Sentence Reduction Using Support Vector Minh Le Nguyen, Akira Shimazu, Sus Bao Tu Ho and Masar
Résumé         : This paper investigates a novel application of support vector machines (SVMs) for sentence reduction. We also propose a new probabilistic sentence reduction method based on support vector machine learning. Experimental results show that the proposed methods outperform earlier methods in term of sentence reduction performance.
Lignes totales : 460
Lignes résumé  : 8
Longueur texte : 327 caractères
Temps analyse  : 3 ms

==============================
Traitement terminé en 44 ms
==============================
Fichier        : Stolcke_1996_Automatic_linguistic.txt
Titre          : AUTOMATIC LINGUISTIC SEGMENTATION OF CONVERSATIONAL SPEECH Andreas Stolcke                             Eliz
Résumé         : to h As speech recognition moves toward more unconstrained domains trie such as conversational speech, we encounter a need to be able to cess segment (or resegment) waveforms and recognizer output into lin segm guistically meaningful units, such a sentences. Toward this end, we present a simple automatic segmenter of transcripts based on Our N-gram language modeling. We also study the relevance of sev lang eral word-level features for segmentation performance. Using only guag word-level information, we achieve 85% recall and 70% precision mode on linguistic boundary detection. ment [10]
Lignes totales : 249
Lignes résumé  : 11
Longueur texte : 593 caractères
Temps analyse  : 2 ms

==============================
Traitement terminé en 46 ms
==============================
Fichier        : Torres.txt
Titre          : Summary Evaluation with and without References Juan-Manuel Torres-Moreno, Horacio Saggion, Iria da Cunha, Eric SanJu
Résumé         : the evaluation of text summarization systems without human models which is used to produce system rankings. The research is carried out using a new content-based evaluation framework called FRESA to compute a variety of divergences among probability distributions. We apply our comparison framework to various well-established content-based evaluation measures in text summarization such as COVERAGE, RESPONSIVENESS, PYRAMIDS and ROUGE studying their associations in various text summarization tasks including generic multi-document summarization in English and French, focus-based multi-document summarization in English and generic single-document summarization in French and Spanish.
Lignes totales : 517
Lignes résumé  : 13
Longueur texte : 686 caractères
Temps analyse  : 5 ms

==============================
Traitement terminé en 52 ms
==============================
Fichier        : Word2Vec.txt
Titre          : Efﬁcient Estimation of Word Representations in Vector Space arXiv:1301.3781v3 [cs.CL] 7 Sep 2013      Tomas Mikolov           Kai Chen
Résumé         : We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.
Lignes totales : 735
Lignes résumé  : 9
Longueur texte : 644 caractères
Temps analyse  : 3 ms

==============================
Traitement terminé en 56 ms
