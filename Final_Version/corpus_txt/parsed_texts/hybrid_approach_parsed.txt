hybrid_approach.txt
    Sentence Compression for Automated Subtitling: A Hybrid Approach
                           scribed in this paper is not a subtitling tool. When                                                          subtitling, only when a sentence needs to be re- In this paper a sentence compression tool is de-                                                          duced, and the amount of reduction is known, the scribed. We describe how an input sentence gets                                                          sentence is sent to the sentence compression tool. analysed by using a.o. a tagger, a shallow parser                                                          So the sentence compression tool is a module of an and a subordinate clause detector, and how, based                                                          automated subtitling tool. The output of the sen- on this analysis, several compressed versions of this                                                          tence compression tool needs to be processed ac- sentence are generated, each with an associated es-                                                          cording to the subtitling guidelines like (Dewulf and timated probability. These probabilities were esti-                                                          Saerens, 2000), in order to be in the correct lay-out mated from a parallel transcript/subtitle corpus. To                                                          which makes it usable for actual subtitling. Manu- avoid ungrammatical sentences, the tool also makes                                                          ally post-editing the subtitles will still be required, use of a number of rules. The evaluation was done                                                          as for some sentences no automatic compression is on three different pronunciation speeds, averaging                                                          generated. sentence reduction rates of 40% to 17%. The num-                                                             In real subtitling it often occurs that the sentences ber of reasonable reductions ranges between 32.9%                                                          are not compressed, but to keep the subtitles syn- and 51%, depending on the average estimated pro-                                                          chronized with the speech, some sentences are en- nunciation speed.                                                          tirely removed.                                                             In section 2 we describe the processing of a sen- 1 Introduction                                           tence in the sentence compressor, from input to out- A sentence compression tool has been built with          put. In section 3 we describe how the system was the purpose of automating subtitle generation for        evaluated and the results of the evaluation. Section the deaf and hard-of-hearing. Verbatim transcrip-        4 contains the conclusions. tions cannot be presented as the subtitle presentation time is between 690 and 780 characters per minute,       2 From Full Sentence to Compressed which is more or less 5.5 seconds for two lines (ITC,      Sentence 1997), (Dewulf and Saerens, 2000), while the aver-       The sentence compression tool is inspired by (Jing, age speech rate contains a lot more than the equiva-     2001). Although her goal is text summarization lent of 780 characters per minute.                       and not subtitling, her sentence compression system    The actual amount of compression needed de-           could serve this purpose. pends on the speed of the speaker and on the amount         She uses multiple sources of knowledge on which of time available after the sentence. In documen-        her sentence reduction is based. She makes use of taries, for instance, there are often large silent in-   a corpus of sentences, aligned with human-written tervals between two sentences, the speech is often       sentence reductions which is similar to the parallel slower and the speaker is off-screen, so the avail-      corpus we use (Vandeghinste and Tjong Kim Sang, able presentation time is longer. When the speaker       2004). She applies a syntactic parser to analyse the is off-screen, the synchrony of the subtitles with       syntactic structure of the input sentences. As there the speech is of minor importance. When subti-           was no syntactic parser available for Dutch (Daele- tling the news the speech rate is often very high        mans and Strik, 2002), we created ShaRPA (Van- so the amount of reduction needed to allow the           deghinste, submitted), a shallow rule-based parser synchronous presentation of subtitles and speech is      which could give us a shallow parse tree of the much greater. The sentence compression rate is a         input sentence. Jing uses several other knowl- parameter which can be set for each sentence.            edge sources, which are not used (not available for    Note that the sentence compression tool de-           Dutch) or not yet used in our system (like WordNet).    In figure 1 the processing flow of an input sen-      comes EU) and replaces the full form with its ab- tence is sketched.                                       breviation. The database can also contain the tag                                                          of the abbreviated part (E.g. the tag for EU is         Input Sentence                                   N(eigen,zijd,ev,basis,stan) [E: singular non-neuter                                                          proper noun]).             Tagger                                                             In a third step, all numbers which are written in                                                          words in the input are replaced by their form in dig-                                                          its. This is done for all numbers which are smaller          Abbreviator                                     than one million, both for cardinal and ordinal nu-                                                          merals.       Numbers to Digits                                                             In a fourth step, the sentence is sent to ShaRPa,                                                          which will result in a shallow parse-tree of the sen-                                                          tence. The chunking accuracy for noun phrases            Chunker                                       (NPs) has an F-value of 94.7%, while the chunk-                                                          ing accuracy of prepositional phrases (PPs) has an   Subordinate Clause Detector                                                          F-value of 95.1% (Vandeghinste, submitted).                                                             A last step before the actual sentence compres-                                                          sion consists of rule-based clause-detection: Rel-         Shallow Parse              Tree                                        ative phrases (RELP), subordinate clauses (SSUB)                                 Grammar                  and OTI-phrases (OTI is om ... te + infinitive1 ) are                                 Rules                                                          detected. The accuracy of these detections was eval-                                                          uated on 30 files from the CGN component of read-                                 Removal,                 aloud books, which contained 7880 words. The         Compressor                                 Nonâˆ’removal,             evaluation results are presented in table 1.                                 Reduction                                 Database                                                                 Type of S   Precision      Recall     F-value                                                                 OTI          71.43%       65.22%      68.18%                                 Word Reducer                                                                 RELP         69.66%       68.89%      69.27%          Compressed           Sentence                                              SSUB         56.83%       60.77%      58.74%
